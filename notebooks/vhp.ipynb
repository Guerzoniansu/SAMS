{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'netcdf4': <NetCDF4BackendEntrypoint>\n",
      "  Open netCDF (.nc, .nc4 and .cdf) and most HDF5 files using netCDF4 in Xarray\n",
      "  Learn more at https://docs.xarray.dev/en/stable/generated/xarray.backends.NetCDF4BackendEntrypoint.html, 'h5netcdf': <H5netcdfBackendEntrypoint>\n",
      "  Open netCDF (.nc, .nc4 and .cdf) and most HDF5 files using h5netcdf in Xarray\n",
      "  Learn more at https://docs.xarray.dev/en/stable/generated/xarray.backends.H5netcdfBackendEntrypoint.html, 'scipy': <ScipyBackendEntrypoint>\n",
      "  Open netCDF files (.nc, .nc4, .cdf and .gz) using scipy in Xarray\n",
      "  Learn more at https://docs.xarray.dev/en/stable/generated/xarray.backends.ScipyBackendEntrypoint.html, 'store': <StoreBackendEntrypoint>\n",
      "  Open AbstractDataStore instances in Xarray\n",
      "  Learn more at https://docs.xarray.dev/en/stable/generated/xarray.backends.StoreBackendEntrypoint.html}\n"
     ]
    }
   ],
   "source": [
    "print(xr.backends.list_engines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform VHP files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../vhp/VHP.G04.C07.j01.P2020001.ND.nc')\n",
    "df_nd = ds.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nd.drop(['HEIGHT', 'WIDTH', 'QA', 'PLATE_CARREE'], axis=1, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          NDVI  BT4   latitude   longitude\n",
      "36159995   NaN  NaN -55.133991  179.837982\n",
      "36159996   NaN  NaN -55.133991  179.873978\n",
      "36159997   NaN  NaN -55.133991  179.909988\n",
      "36159998   NaN  NaN -55.133991  179.945984\n",
      "36159999   NaN  NaN -55.133991  179.981979\n"
     ]
    }
   ],
   "source": [
    "print(df_nd.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../vhp/VHP.G04.C07.j01.P2020001.VH.nc')\n",
    "df_vh = ds.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vh.drop(['HEIGHT', 'WIDTH', 'QA', 'PLATE_CARREE'], axis=1, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          VCI  TCI  VHI   latitude   longitude\n",
      "36159995  NaN  NaN  NaN -55.133991  179.837982\n",
      "36159996  NaN  NaN  NaN -55.133991  179.873978\n",
      "36159997  NaN  NaN  NaN -55.133991  179.909988\n",
      "36159998  NaN  NaN  NaN -55.133991  179.945984\n",
      "36159999  NaN  NaN  NaN -55.133991  179.981979\n"
     ]
    }
   ],
   "source": [
    "print(df_vh.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.merge(df_nd, df_vh, on=['latitude', 'longitude'], suffixes=('_ND', '_VH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          NDVI  BT4   latitude   longitude  VCI  TCI  VHI\n",
      "36159995   NaN  NaN -55.133991  179.837982  NaN  NaN  NaN\n",
      "36159996   NaN  NaN -55.133991  179.873978  NaN  NaN  NaN\n",
      "36159997   NaN  NaN -55.133991  179.909988  NaN  NaN  NaN\n",
      "36159998   NaN  NaN -55.133991  179.945984  NaN  NaN  NaN\n",
      "36159999   NaN  NaN -55.133991  179.981979  NaN  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "print(dt.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Week CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\SAMS\\\\notebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\SAMS\\vhp\n"
     ]
    }
   ],
   "source": [
    "vhp = os.path.dirname(os.getcwd())\n",
    "vhp = os.path.join(vhp, \"vhp\")\n",
    "print(vhp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = os.path.join(vhp, \"csv\")\n",
    "os.makedirs(cf, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = os.path.join(vhp, \"monthly\")\n",
    "os.makedirs(mf, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openTransformMergeNDVH(np: str, vp: str):\n",
    "    ds_nd = xr.open_dataset(np)\n",
    "    ds_vh = xr.open_dataset(vp)\n",
    "    \n",
    "    df_nd = ds_nd.to_dataframe().reset_index()\n",
    "    df_vh = ds_vh.to_dataframe().reset_index()\n",
    "\n",
    "    # drop useless variables\n",
    "    df_nd.drop(['HEIGHT', 'WIDTH', 'QA', 'PLATE_CARREE'], axis=1, errors='ignore', inplace=True)\n",
    "    df_vh.drop(['HEIGHT', 'WIDTH', 'QA', 'PLATE_CARREE'], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "    # drop na lines for interest variables\n",
    "    df_nd.dropna(subset=['NDVI', 'BT4'], inplace=True)\n",
    "    df_vh.dropna(subset=['VCI', 'TCI', 'VHI'], inplace=True)\n",
    "    \n",
    "    merged_df = pd.merge(df_nd, df_vh, on=['latitude', 'longitude'], suffixes=('_ND', '_VH'))\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveNDVH(np: str, vp: str, week: str, nd_file: str, vh_file: str):\n",
    "    if os.path.exists(np) and os.path.exists(vp):\n",
    "        df = openTransformMergeNDVH(np, vp)\n",
    "        csv_filename = f\"VHP.G04.C07.j01.P2020{week}.csv\"\n",
    "        csv_path = os.path.join(cf, csv_filename)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(f\"Saved merged data for week {week} to {csv_path}\")\n",
    "    else:\n",
    "        print(f\"One or both files missing for week {week}: {nd_file}, {vh_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged data for week 001 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020001.csv\n",
      "Saved merged data for week 002 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020002.csv\n",
      "Saved merged data for week 003 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020003.csv\n",
      "Saved merged data for week 004 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020004.csv\n",
      "Saved merged data for week 005 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020005.csv\n",
      "Saved merged data for week 006 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020006.csv\n",
      "Saved merged data for week 007 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020007.csv\n",
      "Saved merged data for week 008 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020008.csv\n",
      "Saved merged data for week 009 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020009.csv\n",
      "Saved merged data for week 010 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020010.csv\n",
      "Saved merged data for week 011 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020011.csv\n",
      "Saved merged data for week 012 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020012.csv\n",
      "Saved merged data for week 013 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020013.csv\n",
      "Saved merged data for week 014 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020014.csv\n",
      "Saved merged data for week 015 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020015.csv\n",
      "Saved merged data for week 016 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020016.csv\n",
      "Saved merged data for week 017 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020017.csv\n",
      "Saved merged data for week 018 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020018.csv\n",
      "Saved merged data for week 019 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020019.csv\n",
      "Saved merged data for week 020 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020020.csv\n",
      "Saved merged data for week 021 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020021.csv\n",
      "Saved merged data for week 022 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020022.csv\n",
      "Saved merged data for week 023 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020023.csv\n",
      "Saved merged data for week 024 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020024.csv\n",
      "Saved merged data for week 025 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020025.csv\n",
      "Saved merged data for week 026 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020026.csv\n",
      "Saved merged data for week 027 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020027.csv\n",
      "Saved merged data for week 028 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020028.csv\n",
      "Saved merged data for week 029 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020029.csv\n",
      "Saved merged data for week 030 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020030.csv\n",
      "Saved merged data for week 031 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020031.csv\n",
      "Saved merged data for week 032 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020032.csv\n",
      "Saved merged data for week 033 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020033.csv\n",
      "Saved merged data for week 034 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020034.csv\n",
      "Saved merged data for week 035 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020035.csv\n",
      "Saved merged data for week 036 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020036.csv\n",
      "Saved merged data for week 037 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020037.csv\n",
      "Saved merged data for week 038 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020038.csv\n",
      "Saved merged data for week 039 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020039.csv\n",
      "Saved merged data for week 040 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020040.csv\n",
      "Saved merged data for week 041 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020041.csv\n",
      "Saved merged data for week 042 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020042.csv\n",
      "Saved merged data for week 043 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020043.csv\n",
      "Saved merged data for week 044 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020044.csv\n",
      "Saved merged data for week 045 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020045.csv\n",
      "Saved merged data for week 046 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020046.csv\n",
      "Saved merged data for week 047 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020047.csv\n",
      "Saved merged data for week 048 to e:\\SAMS\\vhp\\csv\\VHP.G04.C07.j01.P2020048.csv\n"
     ]
    }
   ],
   "source": [
    "for week in range(1, 49):\n",
    "    week_str = str(week).zfill(3)\n",
    "    nd_file = f\"VHP.G04.C07.j01.P2020{week_str}.ND.nc\"\n",
    "    vh_file = f\"VHP.G04.C07.j01.P2020{week_str}.VH.nc\"\n",
    "    \n",
    "    nd_path = os.path.join(vhp, nd_file)\n",
    "    vh_path = os.path.join(vhp, vh_file)\n",
    "    \n",
    "    saveNDVH(nd_path, vh_path, week_str, nd_file, vh_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Monthly CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort files in CSV folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = sorted([f for f in os.listdir(cf) if f.endswith('.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VHP.G04.C07.j01.P2020001.csv', 'VHP.G04.C07.j01.P2020002.csv', 'VHP.G04.C07.j01.P2020003.csv', 'VHP.G04.C07.j01.P2020004.csv', 'VHP.G04.C07.j01.P2020005.csv', 'VHP.G04.C07.j01.P2020006.csv', 'VHP.G04.C07.j01.P2020007.csv', 'VHP.G04.C07.j01.P2020008.csv', 'VHP.G04.C07.j01.P2020009.csv', 'VHP.G04.C07.j01.P2020010.csv', 'VHP.G04.C07.j01.P2020011.csv', 'VHP.G04.C07.j01.P2020012.csv', 'VHP.G04.C07.j01.P2020013.csv', 'VHP.G04.C07.j01.P2020014.csv', 'VHP.G04.C07.j01.P2020015.csv', 'VHP.G04.C07.j01.P2020016.csv', 'VHP.G04.C07.j01.P2020017.csv', 'VHP.G04.C07.j01.P2020018.csv', 'VHP.G04.C07.j01.P2020019.csv', 'VHP.G04.C07.j01.P2020020.csv', 'VHP.G04.C07.j01.P2020021.csv', 'VHP.G04.C07.j01.P2020022.csv', 'VHP.G04.C07.j01.P2020023.csv', 'VHP.G04.C07.j01.P2020024.csv', 'VHP.G04.C07.j01.P2020025.csv', 'VHP.G04.C07.j01.P2020026.csv', 'VHP.G04.C07.j01.P2020027.csv', 'VHP.G04.C07.j01.P2020028.csv', 'VHP.G04.C07.j01.P2020029.csv', 'VHP.G04.C07.j01.P2020030.csv', 'VHP.G04.C07.j01.P2020031.csv', 'VHP.G04.C07.j01.P2020032.csv', 'VHP.G04.C07.j01.P2020033.csv', 'VHP.G04.C07.j01.P2020034.csv', 'VHP.G04.C07.j01.P2020035.csv', 'VHP.G04.C07.j01.P2020036.csv', 'VHP.G04.C07.j01.P2020037.csv', 'VHP.G04.C07.j01.P2020038.csv', 'VHP.G04.C07.j01.P2020039.csv', 'VHP.G04.C07.j01.P2020040.csv', 'VHP.G04.C07.j01.P2020041.csv', 'VHP.G04.C07.j01.P2020042.csv', 'VHP.G04.C07.j01.P2020043.csv', 'VHP.G04.C07.j01.P2020044.csv', 'VHP.G04.C07.j01.P2020045.csv', 'VHP.G04.C07.j01.P2020046.csv', 'VHP.G04.C07.j01.P2020047.csv', 'VHP.G04.C07.j01.P2020048.csv']\n"
     ]
    }
   ],
   "source": [
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openMergeCSVFilesFourSet(months: list[str]):\n",
    "    dfs = [pd.read_csv(os.path.join(cf, f)) for f in months]\n",
    "    print(\"Finished loading data...\")\n",
    "\n",
    "    #rename df columns\n",
    "    for i, df in enumerate(dfs):\n",
    "        df.rename(columns={'NDVI': f'NDVI{i}', 'BT4': f'BT4{i}', 'VCI': f'VCI{i}', 'TCI': f'TCI{i}', 'VHI': f'VHI{i}'}, inplace=True)\n",
    "    \n",
    "    # merge on latitude and longitude\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=['latitude', 'longitude'], suffixes=('', ''))\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanMergedDf(df: pd.DataFrame):\n",
    "    mean_columns = {}\n",
    "    for prefix in ['NDVI', 'BT4', 'VCI', 'TCI', 'VHI']:\n",
    "        cols_to_average = [col for col in df.columns if col.startswith(prefix)]\n",
    "        mean_columns[prefix] = df[cols_to_average].mean(axis=1)\n",
    "\n",
    "    mean_df = pd.DataFrame(mean_columns)\n",
    "    # Add latitude and longitude columns from the df\n",
    "    mean_df['latitude'] = df['latitude']\n",
    "    mean_df['longitude'] = df['longitude']\n",
    "    return mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMonthMeanData(df: pd.DataFrame, i: int):\n",
    "    month_num = (i // 4) + 1  # Month counter based on weeks processed\n",
    "    monthly_csv_path = os.path.join(mf, f\"VHP.G04.C07.j01.P2020_month{month_num:02d}.csv\")\n",
    "    df.to_csv(monthly_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Saved merged monthly data to {monthly_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month01.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month02.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month03.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month04.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month05.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month06.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month07.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month08.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month09.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month10.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month11.csv\n",
      "Finished loading data...\n",
      "Saved merged monthly data to e:\\SAMS\\vhp\\monthly\\VHP.G04.C07.j01.P2020_month12.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(csv_files), 4):\n",
    "    monthly_files = csv_files[i:i + 4]\n",
    "    \n",
    "    merged_df = openMergeCSVFilesFourSet(monthly_files)\n",
    "    mean_df = calculateMeanMergedDf(merged_df)\n",
    "    \n",
    "    saveMonthMeanData(mean_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = os.path.join(vhp, \"monthly\")\n",
    "os.makedirs(mf, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(vhp, \"global\")\n",
    "os.makedirs(df, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYearData(months: list[str]):\n",
    "    dfs = [pd.read_csv(os.path.join(mf, f)) for f in months]\n",
    "    print(\"Finished loading data...\")\n",
    "\n",
    "    #rename df columns\n",
    "    for i, df in enumerate(dfs):\n",
    "        df.rename(columns={'NDVI': f'NDVI{i}', 'BT4': f'BT4{i}', 'VCI': f'VCI{i}', 'TCI': f'TCI{i}', 'VHI': f'VHI{i}'}, inplace=True)\n",
    "    \n",
    "    # merge on latitude and longitude\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=['latitude', 'longitude'], suffixes=('', ''))\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data...\n"
     ]
    }
   ],
   "source": [
    "monthly_files = sorted([f for f in os.listdir(mf) if f.endswith('.csv')])\n",
    "yearVhpDf = getYearData(monthly_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI0</th>\n",
       "      <th>BT40</th>\n",
       "      <th>VCI0</th>\n",
       "      <th>TCI0</th>\n",
       "      <th>VHI0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>NDVI1</th>\n",
       "      <th>BT41</th>\n",
       "      <th>VCI1</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI10</th>\n",
       "      <th>BT410</th>\n",
       "      <th>VCI10</th>\n",
       "      <th>TCI10</th>\n",
       "      <th>VHI10</th>\n",
       "      <th>NDVI11</th>\n",
       "      <th>BT411</th>\n",
       "      <th>VCI11</th>\n",
       "      <th>TCI11</th>\n",
       "      <th>VHI11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7979576</th>\n",
       "      <td>0.41075</td>\n",
       "      <td>276.825005</td>\n",
       "      <td>97.942500</td>\n",
       "      <td>12.477500</td>\n",
       "      <td>55.212499</td>\n",
       "      <td>-55.13399</td>\n",
       "      <td>-67.482000</td>\n",
       "      <td>0.40100</td>\n",
       "      <td>280.075000</td>\n",
       "      <td>74.144999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29150</td>\n",
       "      <td>275.825010</td>\n",
       "      <td>60.830000</td>\n",
       "      <td>10.040000</td>\n",
       "      <td>35.434999</td>\n",
       "      <td>0.54225</td>\n",
       "      <td>284.925005</td>\n",
       "      <td>96.837500</td>\n",
       "      <td>4.205000</td>\n",
       "      <td>50.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979577</th>\n",
       "      <td>0.39725</td>\n",
       "      <td>277.975005</td>\n",
       "      <td>38.942500</td>\n",
       "      <td>24.402499</td>\n",
       "      <td>31.674999</td>\n",
       "      <td>-55.13399</td>\n",
       "      <td>-67.446010</td>\n",
       "      <td>0.45300</td>\n",
       "      <td>284.125005</td>\n",
       "      <td>48.954999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31000</td>\n",
       "      <td>273.150010</td>\n",
       "      <td>54.385000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>37.362499</td>\n",
       "      <td>0.57225</td>\n",
       "      <td>287.700000</td>\n",
       "      <td>69.704999</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>40.234999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979578</th>\n",
       "      <td>0.44675</td>\n",
       "      <td>282.850000</td>\n",
       "      <td>72.522499</td>\n",
       "      <td>10.457500</td>\n",
       "      <td>41.489999</td>\n",
       "      <td>-55.13399</td>\n",
       "      <td>-67.410000</td>\n",
       "      <td>0.50750</td>\n",
       "      <td>284.075000</td>\n",
       "      <td>62.307499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29550</td>\n",
       "      <td>268.050005</td>\n",
       "      <td>40.082500</td>\n",
       "      <td>44.337499</td>\n",
       "      <td>42.207499</td>\n",
       "      <td>0.60825</td>\n",
       "      <td>287.900010</td>\n",
       "      <td>60.267499</td>\n",
       "      <td>35.365000</td>\n",
       "      <td>47.817499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979579</th>\n",
       "      <td>0.33425</td>\n",
       "      <td>274.000010</td>\n",
       "      <td>67.565000</td>\n",
       "      <td>13.280000</td>\n",
       "      <td>40.424999</td>\n",
       "      <td>-55.13399</td>\n",
       "      <td>-67.158005</td>\n",
       "      <td>0.51175</td>\n",
       "      <td>287.050010</td>\n",
       "      <td>72.565000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40475</td>\n",
       "      <td>280.375005</td>\n",
       "      <td>64.029999</td>\n",
       "      <td>14.917500</td>\n",
       "      <td>39.472499</td>\n",
       "      <td>0.49825</td>\n",
       "      <td>283.700005</td>\n",
       "      <td>75.599999</td>\n",
       "      <td>28.092499</td>\n",
       "      <td>51.844999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979580</th>\n",
       "      <td>0.36650</td>\n",
       "      <td>279.100005</td>\n",
       "      <td>76.495000</td>\n",
       "      <td>11.942500</td>\n",
       "      <td>44.220000</td>\n",
       "      <td>-55.13399</td>\n",
       "      <td>-67.122000</td>\n",
       "      <td>0.55025</td>\n",
       "      <td>287.100005</td>\n",
       "      <td>79.979999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48650</td>\n",
       "      <td>282.650000</td>\n",
       "      <td>75.649999</td>\n",
       "      <td>21.372500</td>\n",
       "      <td>48.512499</td>\n",
       "      <td>0.51750</td>\n",
       "      <td>283.150005</td>\n",
       "      <td>83.507497</td>\n",
       "      <td>19.054999</td>\n",
       "      <td>51.282499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NDVI0        BT40       VCI0       TCI0       VHI0  latitude  \\\n",
       "7979576  0.41075  276.825005  97.942500  12.477500  55.212499 -55.13399   \n",
       "7979577  0.39725  277.975005  38.942500  24.402499  31.674999 -55.13399   \n",
       "7979578  0.44675  282.850000  72.522499  10.457500  41.489999 -55.13399   \n",
       "7979579  0.33425  274.000010  67.565000  13.280000  40.424999 -55.13399   \n",
       "7979580  0.36650  279.100005  76.495000  11.942500  44.220000 -55.13399   \n",
       "\n",
       "         longitude    NDVI1        BT41       VCI1  ...   NDVI10       BT410  \\\n",
       "7979576 -67.482000  0.40100  280.075000  74.144999  ...  0.29150  275.825010   \n",
       "7979577 -67.446010  0.45300  284.125005  48.954999  ...  0.31000  273.150010   \n",
       "7979578 -67.410000  0.50750  284.075000  62.307499  ...  0.29550  268.050005   \n",
       "7979579 -67.158005  0.51175  287.050010  72.565000  ...  0.40475  280.375005   \n",
       "7979580 -67.122000  0.55025  287.100005  79.979999  ...  0.48650  282.650000   \n",
       "\n",
       "             VCI10      TCI10      VHI10   NDVI11       BT411      VCI11  \\\n",
       "7979576  60.830000  10.040000  35.434999  0.54225  284.925005  96.837500   \n",
       "7979577  54.385000  20.340000  37.362499  0.57225  287.700000  69.704999   \n",
       "7979578  40.082500  44.337499  42.207499  0.60825  287.900010  60.267499   \n",
       "7979579  64.029999  14.917500  39.472499  0.49825  283.700005  75.599999   \n",
       "7979580  75.649999  21.372500  48.512499  0.51750  283.150005  83.507497   \n",
       "\n",
       "             TCI11      VHI11  \n",
       "7979576   4.205000  50.522500  \n",
       "7979577  10.760000  40.234999  \n",
       "7979578  35.365000  47.817499  \n",
       "7979579  28.092499  51.844999  \n",
       "7979580  19.054999  51.282499  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearVhpDf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalPath = os.path.join(df, \"VHP.G04.C07.j01.P2020.csv\")\n",
    "yearVhpDf.to_csv(globalPath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VHP Variables to AgriClimate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\SAMS\\datasets\n"
     ]
    }
   ],
   "source": [
    "datasets = os.path.dirname(os.getcwd())\n",
    "datasets = os.path.join(datasets, \"datasets\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = os.path.join(vhp, \"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearVhpDf = pd.read_csv(os.path.join(gf, \"VHP.G04.C07.j01.P2020.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
